{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the model on generated dataset to simulate focal stacking for qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import torch\n",
    "import torchvision\n",
    "# import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "iter = 0\n",
    "num_channels, img_size, img_size = 3, 512, 512\n",
    "output_folder = f'output/synthesized{iter}'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "input = f'input/synthesized{iter}'\n",
    "if not os.path.exists(input):\n",
    "    os.makedirs(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def gradient_blur(image, position, blur_size):\n",
    "    # image: a torch tensor of shape [C, H, W]\n",
    "    # position: a tuple of (x, y) coordinates\n",
    "    # returns: a blurred image tensor of the same shape as input\n",
    "\n",
    "    # get the image height and width\n",
    "    height = image.shape[1]\n",
    "    width = image.shape[2]\n",
    "\n",
    "\n",
    "    # make sure the blur size is odd and at least 3\n",
    "    blur_size = max(3, blur_size + (1 - blur_size % 2))\n",
    "\n",
    "    # set the x range to cover the full width of the image\n",
    "    y_min = 0\n",
    "    y_max = width\n",
    "\n",
    "    # get the y range for the blur region\n",
    "    x_min = max(0, position - blur_size // 2)\n",
    "    x_max = min(height, position + blur_size // 2 + 1)\n",
    "\n",
    "    # crop the blur region from the image\n",
    "    blur_region = image[:, x_min:x_max, y_min:y_max]\n",
    "\n",
    "    # apply gaussian blur to the region\n",
    "    blurred_region = F.gaussian_blur(blur_region, kernel_size=blur_size)\n",
    "\n",
    "    # replace the original region with the blurred one\n",
    "    image[:, x_min:x_max, y_min:y_max] = blurred_region\n",
    "\n",
    "    # return the blurred image\n",
    "    return image\n",
    "\n",
    "# Define a function that takes an image and returns a stacked image\n",
    "def stack_images(image, num_images):\n",
    "    # Define the number of images and the image size\n",
    "    img_size = image.size[0]\n",
    "\n",
    "    # Convert the image to a tensor\n",
    "    tensor = torchvision.transforms.ToTensor()(image)\n",
    "\n",
    "    # Define the jitter and warp parameters\n",
    "    jitter = 3 # The maximum amount of random shift in pixels\n",
    "    warp = 0.005 # The maximum amount of random distortion in fraction of image size\n",
    "\n",
    "    # Create a list of tensors and apply jitter and warp transformations\n",
    "    tensors = []\n",
    "    for i in range(num_images):\n",
    "        # Randomly shift the tensor by a small amount\n",
    "        dx = np.random.randint(-jitter, jitter + 1) # Random x shift\n",
    "        dy = np.random.randint(-jitter, jitter + 1) # Random y shift\n",
    "        shifted_tensor = torch.roll(tensor, shifts=(dx, dy), dims=(1, 2))\n",
    "\n",
    "        # Randomly distort the tensor by a small amount\n",
    "        dw = np.random.uniform(-warp, warp) * img_size # Random width distortion\n",
    "        dh = np.random.uniform(-warp, warp) * img_size # Random height distortion\n",
    "        distorted_tensor = torchvision.transforms.functional.affine(shifted_tensor, angle=0, translate=(0, 0), scale=1, shear=(dw, dh))\n",
    "\n",
    "        # Append the distorted tensor to the list\n",
    "        tensors.append(distorted_tensor)\n",
    "\n",
    "    # # Stack the tensors along the horizontal axis\n",
    "    # stacked_tensor = torch.cat(tensors, dim=2)\n",
    "\n",
    "    # # Convert the stacked tensor to a PIL image\n",
    "    # stacked_image = torchvision.transforms.ToPILImage()(stacked_tensor)\n",
    "\n",
    "    # Return the stacked image\n",
    "    return tensors\n",
    "\n",
    "\n",
    "# Create an image using the previous code (without plotting)\n",
    "img = torch.zeros(num_channels, img_size, img_size)\n",
    "grad = torch.linspace(0, 1, img_size).view(1, -1).repeat(num_channels, img_size, 1) * torch.linspace(0, 1, img_size).view(-1, 1).repeat(num_channels, 1, img_size)\n",
    "img[0] = grad[0]\n",
    "num_circles = 15\n",
    "for _ in range(num_circles):\n",
    "    x = np.random.randint(0, img_size)\n",
    "    y = np.random.randint(0, img_size)\n",
    "    r = np.random.randint(10, 50)\n",
    "    c = torch.rand(num_channels)\n",
    "    mask = torch.zeros(num_channels, img_size, img_size)\n",
    "    for i in range(img_size):\n",
    "        for j in range(img_size):\n",
    "            dist = ((i - x)**2 + (j - y)**2)**0.5\n",
    "            if dist < r:\n",
    "                mask[:, i, j] = 1\n",
    "    img = img + c.view(-1, 1, 1) * mask\n",
    "img = torch.clamp(img, 0, 1)\n",
    "img = torchvision.transforms.ToPILImage()(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img)\n",
    "plt.imsave(f'input/synthesized{iter}gt.png', img, format=\"png\")\n",
    "plt.show()\n",
    "# Call the stack_images function and plot the result\n",
    "num_images = 20\n",
    "blur_height = img_size//5\n",
    "for iter in range(50):\n",
    "    results = stack_images(img, num_images)\n",
    "    output_folder = f'output/synthesized{iter}'\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    input = f'input/synthesized{iter}'\n",
    "    if not os.path.exists(input):\n",
    "        os.makedirs(input)\n",
    "    j = 0\n",
    "    for result in results:\n",
    "        n = random.randint(0, img_size-blur_height-3)\n",
    "        result = gradient_blur(result, n, blur_height)\n",
    "        image_np = result.numpy()\n",
    "\n",
    "        # Transpose the array to put the channels as the last dimension\n",
    "        image_np = image_np.transpose(1, 2, 0) # or image_np = image_tensor.permute(1, 2, 0).numpy()\n",
    "        \n",
    "\n",
    "        # Plot the image using plt\n",
    "        # plt.imshow(image_np)\n",
    "        plt.imsave(f'input/synthesized{iter}/step{j}.png', image_np, format=\"png\")\n",
    "        # plt.show()\n",
    "        j += 1\n",
    "    iter += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on generated dataset (under construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# create a criterion that measures MSE loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# iterate over all samples\n",
    "for iter in range(50):\n",
    "    # # load the input and target image\n",
    "    # input1 = torchvision.io.read_image(f'output/synthesized{iter}/FAIS_result.png')\n",
    "    # input2 = torchvision.io.read_image(f'output/synthesized{iter}/resize_beseline_result.png')\n",
    "    # target = torchvision.io.read_image(f'output/synthesized{iter}/synthesized{iter}gt.png')\n",
    "\n",
    "# print input and target types\n",
    "input1, input2, target = input1.float(), input2.float(), target.float()\n",
    "# compute the MSE loss\n",
    "mse1 = criterion(input1, target)\n",
    "psnr1 = 10 * np.log10(255**2 / mse1)\n",
    "mse2 = criterion(input2, target)\n",
    "psnr2 = 10 * np.log10(255**2 / mse2)\n",
    "print(\"Lower is better (MSE)\")\n",
    "print(\"our method: \", mse1.item())\n",
    "print(\"Base line: \", mse2.item())\n",
    "print(\"Higher is better (PSNR)\")\n",
    "print(\"our method: \", psnr1.item())\n",
    "print(\"Base line: \", psnr2.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
